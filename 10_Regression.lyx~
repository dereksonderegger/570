#LyX 2.1 created this file. For more info see http://www.lyx.org/
\lyxformat 474
\begin_document
\begin_header
\textclass book
\begin_preamble
\usepackage{a4wide}
\end_preamble
\options a4paper
\use_default_options false
\begin_modules
knitr
\end_modules
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding iso8859-1
\fontencoding global
\font_roman default
\font_sans default
\font_typewriter default
\font_math auto
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100
\font_tt_scale 100
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\spacing single
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 0
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 0
\use_package stackrel 0
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\biblio_style plain
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation skip
\defskip medskip
\quotes_language english
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Chapter
Regression
\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Chunk
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE>>=
\end_layout

\begin_layout Plain Layout

if(file.exists('Global_Knitr_Opts.R')){
\end_layout

\begin_layout Plain Layout

  source('Global_Knitr_Opts.R')
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

opts_chunk$set(fig.path   ='figure/Ch_10_regression/') 
\end_layout

\begin_layout Plain Layout

opts_chunk$set(cache.path = 'cache/Ch_10_regression/')
\end_layout

\begin_layout Plain Layout

opts_chunk$set(cache=TRUE)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<message=FALSE, warning=FALSE>>=
\end_layout

\begin_layout Plain Layout

library(ggplot2)
\end_layout

\begin_layout Plain Layout

library(dplyr)
\end_layout

\begin_layout Plain Layout

library(ggfortify)  # for diagnostic plots in ggplot2 via autoplot()
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset

We continue to want to examine the relationship between a predictor variable
 and a response but now we consider the case that the predictor is continuous
 and the response is also continuous.
 In general we are going to be interested in finding the line that best
 fits the observed data and determining if we should include the predictor
 variable in the model.
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Scrap
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE, fig.height=3, fig.width=5>>=
\end_layout

\begin_layout Plain Layout

n <- 20
\end_layout

\begin_layout Plain Layout

data <- data.frame( x = runif(n, 0, 1) )
\end_layout

\begin_layout Plain Layout

data <- mutate(data, y= 2 + x + rnorm(n, sd=.4))
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

ggplot(data, aes(x=x, y=y)) + geom_point() + geom_smooth(method='lm')
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Pearson's Correlation Coefficient
\end_layout

\begin_layout Standard
We first consider Pearson's correlation coefficient, which is a statistics
 that measures the strength of the linear relationship between the predictor
 and response.
 Consider the following Pearson's correlation statistic
\begin_inset Formula 
\[
r=\frac{\sum_{i=1}^{n}\left(\frac{x_{i}-\bar{x}}{s_{x}}\right)\left(\frac{y_{i}-\bar{y}}{s_{y}}\right)}{n-1}
\]

\end_inset

where 
\begin_inset Formula $x_{i}$
\end_inset

 and 
\begin_inset Formula $y_{i}$
\end_inset

 are the x and y coordinate of the 
\begin_inset Formula $i$
\end_inset

th observation.
 Notice that each parenthesis value is the standardized value of each observatio
n.
 If the x-value is big (greater than 
\begin_inset Formula $\bar{x}$
\end_inset

) and the y-value is large (greater than 
\begin_inset Formula $\bar{y}$
\end_inset

), then after multiplication, the result is positive.
 Likewise if the x-value is small and the y-value is small, both standardized
 values are negative and therefore after multiplication the result is positive.
 If a large x-value is paired with a small y-value, then the first value
 is positive, but the second is negative and so the multiplication result
 is negative.
\end_layout

\begin_layout Scrap

\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE, fig.height=4, fig.width=8>>=
\end_layout

\begin_layout Plain Layout

x <- data$x
\end_layout

\begin_layout Plain Layout

y <- data$y
\end_layout

\begin_layout Plain Layout

plot(x,y, axes=FALSE, xlab='', ylab=''); box();
\end_layout

\begin_layout Plain Layout

ybar <- mean(y)
\end_layout

\begin_layout Plain Layout

xbar <- mean(x)
\end_layout

\begin_layout Plain Layout

abline(v=xbar, lty=2); axis(1, at=xbar, label=expression(bar(x)));
\end_layout

\begin_layout Plain Layout

abline(h=ybar, lty=2); axis(2, at=ybar, label=expression(bar(y)));
\end_layout

\begin_layout Plain Layout

text(xbar-.25, ybar+.25, '-', cex=3)
\end_layout

\begin_layout Plain Layout

text(xbar-.25, ybar-.25, '+', cex=3)
\end_layout

\begin_layout Plain Layout

text(xbar+.25, ybar+.25, '+', cex=3)
\end_layout

\begin_layout Plain Layout

text(xbar+.25, ybar-.25, '-', cex=3)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The following are true about Pearson's correlation coefficient:
\end_layout

\begin_layout Enumerate
\begin_inset Formula $r$
\end_inset

 is unit-less because we have standardized the x and y values.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $-1\le r\le1$
\end_inset

 because of the scaling by 
\begin_inset Formula $n-1$
\end_inset


\end_layout

\begin_layout Enumerate
A negative 
\begin_inset Formula $r$
\end_inset

 denotes a negative relationship between x and y, while a positive value
 of 
\begin_inset Formula $r$
\end_inset

 represents a positive relationship.
\end_layout

\begin_layout Enumerate
\begin_inset Formula $r$
\end_inset

 measures the strength of the 
\emph on
linear
\emph default
 relationship between the predictor and response.
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE, fig.height=6, fig.width=8>>=
\end_layout

\begin_layout Plain Layout

par(mfrow=c(2,3))
\end_layout

\begin_layout Plain Layout

x <- seq(0,1, length=n)
\end_layout

\begin_layout Plain Layout

y <- array(NA, dim=c(5, n))
\end_layout

\begin_layout Plain Layout

y[1,] <- 2 + 2*x + rnorm(n, sd=.5)
\end_layout

\begin_layout Plain Layout

y[2,] <- 2 - 2*x + rnorm(n, sd=.5)
\end_layout

\begin_layout Plain Layout

y[3,] <- 2 + 2*x + rnorm(n, sd=.1)
\end_layout

\begin_layout Plain Layout

y[4,] <- 2 + 2*x + rnorm(n, sd=5)
\end_layout

\begin_layout Plain Layout

y[5,] <- 2*(2*x-1)^2 + rnorm(n, sd=.2)
\end_layout

\begin_layout Plain Layout

for( i in 1:5 ){
\end_layout

\begin_layout Plain Layout

  model <- lm(y[i,] ~ x);
\end_layout

\begin_layout Plain Layout

  r <- round(sqrt(summary(model)$r.squared), digits=2) * sign(model$coef[2])
\end_layout

\begin_layout Plain Layout

  plot(x,y[i,], main=paste('r =', r), ylab=i)
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Model Theory
\end_layout

\begin_layout Standard
To scatterplot data that looks linear we often want to fit the model
\begin_inset Formula 
\[
y_{i}=\beta_{0}+\beta_{1}x_{i}+\epsilon_{i}\;\;\;\textrm{where }\epsilon_{i}\stackrel{iid}{\sim}N\left(0,\sigma^{2}\right)
\]

\end_inset

where 
\begin_inset Formula $\beta_{0}$
\end_inset

 is the y-intercept term
\begin_inset Foot
status open

\begin_layout Plain Layout
The y-intercept is the height of the line when 
\begin_inset Formula $x=0$
\end_inset

.
\end_layout

\end_inset

 and 
\begin_inset Formula $\beta_{1}$
\end_inset

 is the slope term
\begin_inset Foot
status open

\begin_layout Plain Layout
The slope is the change in 
\begin_inset Formula $y$
\end_inset

 for every one-unit change in 
\begin_inset Formula $x$
\end_inset


\end_layout

\end_inset

.
 The assumptions of this model are:
\end_layout

\begin_layout Enumerate

\emph on
The relationship between the predictor and response is actually linear
\end_layout

\begin_layout Enumerate

\emph on
The error terms come from a normal distribution
\end_layout

\begin_layout Enumerate

\emph on
The variance of the errors is the same for every value of 
\begin_inset Formula $x$
\end_inset

 (homoscedasticity)
\end_layout

\begin_layout Enumerate

\emph on
The error terms are independent
\end_layout

\begin_layout Standard
Under this model, the expected value of an observation with covariate 
\begin_inset Formula $X=x$
\end_inset

 is 
\begin_inset Formula $E\left(Y\,|\,X=x\right)=\beta_{0}+\beta_{1}x$
\end_inset

 and a new observation has a standard deviation of 
\begin_inset Formula $\sigma$
\end_inset

 about the line.
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE, fig.height=4, fig.width=8>>=
\end_layout

\begin_layout Plain Layout

plot(c(0,1), c(0,1.25), type='n', xlab='x', ylab='y', axes=FALSE);
\end_layout

\begin_layout Plain Layout

box(); axis(1);
\end_layout

\begin_layout Plain Layout

abline(0,1);
\end_layout

\begin_layout Plain Layout

y <- seq(-3,3,length=1000);
\end_layout

\begin_layout Plain Layout

x <- dnorm(y, sd=1);
\end_layout

\begin_layout Plain Layout

x <- x/4;
\end_layout

\begin_layout Plain Layout

y <- y/12;
\end_layout

\begin_layout Plain Layout

for(i in c(.3,.7)){
\end_layout

\begin_layout Plain Layout

	lines(c(i,i), c(min(y), max(y))+i);
\end_layout

\begin_layout Plain Layout

	polygon(x+i, y+i, col='grey');
\end_layout

\begin_layout Plain Layout

	lines(c(i,i+max(x)), c(i,i));
\end_layout

\begin_layout Plain Layout

	text(i,i+.4, expression(paste("", E(Y)==beta[0]+beta[1], x, sep='')));
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Given this model, how do we find estimates of 
\begin_inset Formula $\beta_{0}$
\end_inset

 and 
\begin_inset Formula $\beta_{1}$
\end_inset

? In the past we have always relied on using some sort of sample mean, but
 it is not obvious what we can use here.
 Instead of a mean, we will use the values of 
\begin_inset Formula $\hat{\beta}_{0}$
\end_inset

 and 
\begin_inset Formula $\hat{\beta}_{1}$
\end_inset

 that minimize the sum of squared error (SSE) where
\begin_inset Formula 
\begin{eqnarray*}
\hat{y}_{i} & = & \hat{\beta}_{0}+\hat{\beta}_{1}x_{i}\\
e_{i} & = & y_{i}-\hat{y}_{i}\\
SSE & = & \sum_{i=1}^{n}e_{i}^{2}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
Fortunately there are simple closed form solutions for 
\begin_inset Formula $\hat{\beta}_{0}$
\end_inset

 and 
\begin_inset Formula $\hat{\beta}_{1}$
\end_inset


\begin_inset Formula 
\begin{eqnarray*}
\hat{\beta}_{1} & = & r\,\left(\frac{s_{y}}{s_{x}}\right)\\
\hat{\beta_{0}} & = & \bar{y}-\hat{\beta}_{1}\bar{x}
\end{eqnarray*}

\end_inset

 and using these estimates several properties can be shown
\end_layout

\begin_layout Enumerate
\begin_inset Formula $\hat{\beta}_{0}$
\end_inset

 and 
\begin_inset Formula $\hat{\beta}_{1}$
\end_inset

 are the intercept and slope values that minimize 
\begin_inset Formula $SSE$
\end_inset

.
\end_layout

\begin_layout Enumerate
The regression line goes through the center of mass of the data 
\begin_inset Formula $(\bar{x},\bar{y})$
\end_inset

.
\end_layout

\begin_layout Enumerate
The sum of the residuals is 0.
 That is: 
\begin_inset Formula $\sum e_{i}=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $\hat{\beta}_{0}$
\end_inset

 and 
\begin_inset Formula $\hat{\beta}_{1}$
\end_inset

 are unbiased estimators of 
\begin_inset Formula $\beta_{0}$
\end_inset

 and 
\begin_inset Formula $\beta_{1}$
\end_inset


\end_layout

\begin_layout Standard
We are also interested in an estimate of 
\begin_inset Formula $\sigma^{2}$
\end_inset

 and we will use our usual estimation scheme of 
\begin_inset Formula 
\begin{eqnarray*}
\hat{\sigma}^{2} & = & \frac{1}{n-2}\sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}\\
\\
 & = & \frac{\sum_{i=1}^{n}e_{i}^{2}}{n-2}\\
\\
 & = & \frac{SSE}{n-2}\\
\\
 & = & MSE
\end{eqnarray*}

\end_inset

where the 
\begin_inset Formula $-2$
\end_inset

 comes from having to estimate 
\begin_inset Formula $\beta_{0}$
\end_inset

 and 
\begin_inset Formula $\beta_{1}$
\end_inset

 before we can estimate 
\begin_inset Formula $\sigma^{2}$
\end_inset

.
 As in the ANOVA case, we can interpret 
\begin_inset Formula $\sigma$
\end_inset

 as the typical distance an observation is from its predicted value.
\end_layout

\begin_layout Standard
As always we are also interested in knowing the estimated standard deviation
 (which we will now call 
\emph on
Standard
\emph default
 
\emph on
Error)
\emph default
 of the model parameters 
\begin_inset Formula $\beta_{0}$
\end_inset

 and 
\begin_inset Formula $\beta_{1}$
\end_inset

 and it can be shown that 
\begin_inset Formula 
\[
StdErr\left(\hat{\beta}_{0}\right)=\hat{\sigma}\sqrt{\frac{1}{n}+\frac{\bar{x}^{2}}{S_{xx}}}
\]

\end_inset

and 
\begin_inset Formula 
\[
StdErr\left(\hat{\beta}_{1}\right)=\hat{\sigma}\sqrt{\frac{1}{S_{xx}}}
\]

\end_inset

where 
\begin_inset Formula $S_{xx}=\sum\left(x_{i}-\bar{x}\right)^{2}$
\end_inset

.
 These intervals can be used to calculate confidence intervals for 
\begin_inset Formula $\beta_{0}$
\end_inset

 and 
\begin_inset Formula $\beta_{1}$
\end_inset

 using the formulas: 
\begin_inset Formula 
\[
\hat{\beta}_{i}\pm t_{n-2}^{1-\alpha/2}StdErr\left(\hat{\beta}_{i}\right)
\]

\end_inset


\end_layout

\begin_layout Example*
Again we consider the 
\family typewriter
iris
\family default
 dataset that is available in R.
 I wish to examine the relationship between sepal length and sepal width
 in the species 
\emph on
setosa.
\begin_inset Newline newline
\end_inset


\emph default

\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Scrap
\begin_inset ERT
status open

\begin_layout Plain Layout

<<message=FALSE, fig.height=4, fig.width=8>>=
\end_layout

\begin_layout Plain Layout

library(ggplot2)
\end_layout

\begin_layout Plain Layout

library(dplyr)
\end_layout

\begin_layout Plain Layout

setosa <- filter( iris, Species == 'setosa' )
\end_layout

\begin_layout Plain Layout

ggplot(setosa, aes(x=Sepal.Length, y=Sepal.Width)) +
\end_layout

\begin_layout Plain Layout

  geom_point() +
\end_layout

\begin_layout Plain Layout

  labs(x="Sepal Length", y="Sepal Width", title='Setosa Irises') +
\end_layout

\begin_layout Plain Layout

  theme_bw()
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Scrap
\begin_inset ERT
status open

\begin_layout Plain Layout

<<>>=
\end_layout

\begin_layout Plain Layout

x <- setosa$Sepal.Length
\end_layout

\begin_layout Plain Layout

y <- setosa$Sepal.Width
\end_layout

\begin_layout Plain Layout

n <- length(x)
\end_layout

\begin_layout Plain Layout

r <- sum( (x-mean(x))/sd(x) * (y-mean(y))/sd(y) ) / (n-1)
\end_layout

\begin_layout Plain Layout

b1 <- r*sd(y)/sd(x)
\end_layout

\begin_layout Plain Layout

b0 <- mean(y) - b1*mean(x)
\end_layout

\begin_layout Plain Layout

cbind(r, b0, b1)
\end_layout

\begin_layout Plain Layout

yhat <- b0 + b1*x
\end_layout

\begin_layout Plain Layout

resid <- y - yhat
\end_layout

\begin_layout Plain Layout

SSE <- sum( resid^2 )
\end_layout

\begin_layout Plain Layout

s2 <- SSE/(n-2)
\end_layout

\begin_layout Plain Layout

s2
\end_layout

\begin_layout Plain Layout

Sxx <- sum( (x-mean(x))^2 )
\end_layout

\begin_layout Plain Layout

stderr.b0 <- sqrt(s2) * sqrt( 1/n + mean(x)^2 / Sxx)
\end_layout

\begin_layout Plain Layout

stderr.b1 <- sqrt(s2) * sqrt(1 / Sxx )
\end_layout

\begin_layout Plain Layout

cbind(stderr.b0, stderr.b1)
\end_layout

\begin_layout Plain Layout

t.star <- qt(.975, df=n-2)	
\end_layout

\begin_layout Plain Layout

c(b0-t.star*stderr.b0, b0+t.star*stderr.b0)
\end_layout

\begin_layout Plain Layout

c(b1-t.star*stderr.b1, b1+t.star*stderr.b1)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Example*
Of course, we don't want to have to do these calculations by hand.
 Fortunately statistics packages will do all of the above calculations.
 In R, we will use 
\family typewriter
lm()
\family default
 to fit a linear regression model and then call various accessor functions
 to give me the regression output I want.
\end_layout

\begin_layout Example*
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Scrap
\begin_inset ERT
status open

\begin_layout Plain Layout

<<>>=
\end_layout

\begin_layout Plain Layout

cor( setosa$Sepal.Width,  setosa$Sepal.Length )
\end_layout

\begin_layout Plain Layout

model <- lm(Sepal.Width ~ Sepal.Length, data=setosa)
\end_layout

\begin_layout Plain Layout

coef(model)
\end_layout

\begin_layout Plain Layout

confint(model)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In general, most statistics programs will give a table of output summarizing
 a regression and the table is usually set up as follows:
\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="3" columns="5">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Coefficient
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Estimate
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Standard Error
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
t-stat
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
p-value
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Intercept
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\hat{\beta}_{0}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $StdErr\left(\hat{\beta}_{0}\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $t_{0}=\frac{\hat{\beta}_{0}}{StdErr\left(\hat{\beta}_{0}\right)}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $2*P\left(T_{n-2}>\left|t_{0}\right|\right)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Slope
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $\hat{\beta}_{1}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $StdErr\left(\hat{\beta}_{1}\right)$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $t_{1}=\frac{\hat{\beta}_{1}}{StdErr\left(\hat{\beta}_{1}\right)}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $2*P\left(T_{n-2}>\left|t_{1}\right|\right)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This table is printed by R by using the 
\family typewriter
summary()
\family default
 function:
\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Scrap
\begin_inset ERT
status open

\begin_layout Plain Layout

<<>>=
\end_layout

\begin_layout Plain Layout

model <- lm(Sepal.Width ~ Sepal.Length, data=setosa)
\end_layout

\begin_layout Plain Layout

summary(model)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The first row is giving information about the y-intercept.
 In this case the estimate is 
\begin_inset Formula $-0.5694$
\end_inset

 and the standard error of the estimate is 
\begin_inset Formula $0.5217$
\end_inset

.
 The t-statistic and associated p-value is testing the hypotheses: 
\begin_inset Formula $H_{0}:\,\beta_{0}=0$
\end_inset

 vs 
\begin_inset Formula $H_{a}:\,\beta_{0}\ne0$
\end_inset

.
 This test is not usually of much interest.
 However because the equivalent test in the slope row testing 
\begin_inset Formula $\beta_{1}=0$
\end_inset

 vs 
\begin_inset Formula $\beta_{1}\ne0$
\end_inset

, the p-value of the slope row is 
\emph on
very
\emph default
 interesting because it tells me if I should include the slope variable
 in the model.
 If 
\begin_inset Formula $\beta_{1}$
\end_inset

 could be zero, then we should drop the predictor from our model and use
 the simple model 
\begin_inset Formula $y_{i}=\beta_{0}+\epsilon_{i}$
\end_inset

 instead.
\end_layout

\begin_layout Standard
There are a bunch of other statistics that are returned by 
\family typewriter
summary()
\family default
.
 The 
\family typewriter
Residual standard error
\family default
 is just 
\begin_inset Formula $\hat{\sigma}=\sqrt{MSE}$
\end_inset

 and the degrees of freedom for that error is also given.
 The rest are involved with the ANOVA interpretation of a linear model.
\end_layout

\begin_layout Subsection
Anova Interpretation
\end_layout

\begin_layout Standard
Just as in the ANOVA analysis, we really have a competition between two
 models.
 The full model 
\begin_inset Formula 
\[
y_{i}=\beta_{0}+\beta_{1}x+\epsilon_{i}
\]

\end_inset

vs the simple model where 
\begin_inset Formula $x$
\end_inset

 does not help predict 
\begin_inset Formula $y$
\end_inset

 
\begin_inset Formula 
\[
y_{i}=\mu+\epsilon_{i}
\]

\end_inset

where I've rewritten 
\begin_inset Formula $\beta_{0}=\mu$
\end_inset

 to try to keep our notation straight.
 If I were to look at the simple model I would use 
\begin_inset Formula $\bar{y}=\hat{\mu}$
\end_inset

 as an estimate of 
\begin_inset Formula $\mu$
\end_inset

 and my Sum of Squared Error in the simple model will be
\begin_inset Formula 
\begin{eqnarray*}
SSE_{simple} & = & \sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}\\
 & = & \sum_{i=1}^{n}\left(y_{i}-\hat{\mu}\right)^{2}
\end{eqnarray*}

\end_inset

and the appropriate Mean Squared Error is
\begin_inset Formula 
\[
MSE_{simple}=\frac{1}{n-1}\sum\left(y_{i}-\hat{\mu}\right)^{2}
\]

\end_inset

We can go through the same sort of calculations for the full complex model
 and get
\begin_inset Formula 
\begin{eqnarray*}
SSE_{complex} & = & \sum_{i=1}^{n}\left(y_{i}-\hat{y}_{i}\right)^{2}\\
 & = & \sum_{i=1}^{n}\left(y_{i}-\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{i}\right)\right)^{2}
\end{eqnarray*}

\end_inset

and
\begin_inset Formula 
\[
MSE_{complex}=\frac{1}{n-2}\sum_{i=1}^{n}\left(y_{i}-\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{i}\right)\right)^{2}
\]

\end_inset

Just as in the AVOVA analysis, if we often like to look at the difference
 between 
\begin_inset Formula $SSE_{simple}-SSE_{comples}=SSE_{diff}$
\end_inset

 and think of this quantity as the amount of variability that is explained
 by adding the slope parameter to the model.
 Just as in the AVOVA case we'll calculate
\begin_inset Formula 
\[
MSE_{diff}=SSE_{diff}/df_{diff}
\]

\end_inset

where 
\begin_inset Formula $df_{diff}$
\end_inset

 is the number of parameters that we added to the simple model to create
 the complex one.
 In the simple linear regression case, 
\begin_inset Formula $df_{diff}=1$
\end_inset

.
\end_layout

\begin_layout Standard
Just as in the ANOVA case, we will calculate an f-statistic to test the
 null hypothesis that the simple model suffices vs the alternative that
 the complex model is necessary.
 The calculation is 
\begin_inset Formula 
\[
f=\frac{MSE_{diff}}{MSE_{complex}}
\]

\end_inset

and the associated p-value is 
\begin_inset Formula $P\left(F_{1,n-2}>f\right)$
\end_inset

.
 Notice that this test is 
\emph on
exactly
\emph default
 testing if 
\begin_inset Formula $\beta_{1}=0$
\end_inset

 and therefore the p-value for the F-test and the t-test for 
\begin_inset Formula $\beta_{1}$
\end_inset

 are the same.
 It can easily be shown that 
\begin_inset Formula $t_{1}^{2}=f$
\end_inset

.
 
\end_layout

\begin_layout Standard
The Analysis of Variance table looks the same as what we have seen, but
 now we recognize that the rows actually represent the complex and simple
 models and the difference between them.
\end_layout

\begin_layout Standard
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\noindent
\align center
\begin_inset Tabular
<lyxtabular version="3" rows="4" columns="6">
<features rotate="0" tabularvalignment="middle">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<column alignment="center" valignment="top">
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Source
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
df
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Sum of Squares
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Mean Squared
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
F-value
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
P-value
\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Difference
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
1
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $SSE_{diff}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $MSE_{diff}=\frac{SSE_{diff}}{1}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $f=\frac{MSE_{diff}}{MSE_{complex}}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $P\left(F_{1,\,n-2}>f\right)$
\end_inset


\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Complex
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $n-2$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $SSE_{complex}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $MSE_{complex}=\frac{SSE_{complex}}{n-2}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
<row>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
Simple
\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $n-1$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout
\begin_inset Formula $SSE_{simple}$
\end_inset


\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
<cell alignment="center" valignment="top" topline="true" bottomline="true" leftline="true" rightline="true" usebox="none">
\begin_inset Text

\begin_layout Plain Layout

\end_layout

\end_inset
</cell>
</row>
</lyxtabular>

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
As usual, the ANOVA table for the regression is available in R using the
 
\family typewriter
anova()
\family default
 command.
 
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Scrap
\begin_inset ERT
status open

\begin_layout Plain Layout

<<>>=
\end_layout

\begin_layout Plain Layout

model <- lm(Sepal.Width ~ Sepal.Length, data=setosa)
\end_layout

\begin_layout Plain Layout

anova(model)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
But we notice that R chooses not to display the row corresponding to the
 simple model.
\end_layout

\begin_layout Standard
I could consider 
\begin_inset Formula $SSE_{simple}$
\end_inset

 as a baseline measure of the amount of variability in the data.
 It is interesting to look at how much of that baseline variability has
 been explained by adding the additional parameter to the model.
 Therefore we'll define the ratio 
\begin_inset Formula $R^{2}$
\end_inset

 as:
\begin_inset Formula 
\[
R^{2}=\frac{SSE_{diff}}{SSE_{simple}}=\frac{SSE_{simple}-SSE_{complex}}{SSE_{simple}}=r^{2}
\]

\end_inset

where 
\begin_inset Formula $r$
\end_inset

 is Pearson's Correlation Coefficient.
 
\begin_inset Formula $R^{2}$
\end_inset

 has the wonderful interpretation of the percent of variability in the response
 variable that can be explained by the predictor variable 
\begin_inset Formula $x$
\end_inset

.
 
\end_layout

\begin_layout Subsection
Confidence Intervals vs Prediction Intervals
\end_layout

\begin_layout Standard
There are two different types of questions that we might ask about predicting
 the value for some x-value 
\begin_inset Formula $x_{new}$
\end_inset

.
 
\end_layout

\begin_layout Standard
We might be interested in a confidence interval for regression line.
 For this question we want to know how much would we expect the sample regressio
n line move if we were to collect a new set of data.
 In particular, for some value of 
\begin_inset Formula $x$
\end_inset

, say 
\begin_inset Formula $x_{new}$
\end_inset

, how variable would the regression line be? To answer that we have to ask
 what is the estimated variance of 
\begin_inset Formula $\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}$
\end_inset

? The variance of the regression line will be a function of the variances
 of 
\begin_inset Formula $\hat{\beta}_{0}$
\end_inset

 and 
\begin_inset Formula $\hat{\beta}_{1}$
\end_inset

 and thus the standard error looks somewhat reminiscent of the standard
 errors of 
\begin_inset Formula $\hat{\beta}_{0}$
\end_inset

 and 
\begin_inset Formula $\hat{\beta}_{1}$
\end_inset

.
 Recalling that 
\begin_inset Formula $S_{xx}=\sum\left(x_{i}-\bar{x}\right)^{2}$
\end_inset

, we have:
\begin_inset Formula 
\[
\hat{Var}\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}\right)=\hat{\sigma}^{2}\left(\frac{1}{n}+\frac{\left(x_{new}-\bar{x}\right)^{2}}{S_{xx}}\right)
\]

\end_inset

 and therefore its 
\begin_inset Formula $StdErr(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new})$
\end_inset

 is
\begin_inset Formula 
\[
StdErr\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}\right)=\hat{\sigma}\sqrt{\frac{1}{n}+\frac{\left(x_{new}-\bar{x}\right)^{2}}{S_{xx}}}
\]

\end_inset


\end_layout

\begin_layout Standard
We can use this value to produce a confidence interval for the regression
 line for any value of 
\begin_inset Formula $x_{new}$
\end_inset

.
\begin_inset Formula 
\begin{eqnarray*}
Estimate & \pm & t\;StdErr\left(Estimate\right)\\
\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}\right) & \pm & t_{n-2}^{1-\alpha/2}\;\;\hat{\sigma}\sqrt{\frac{1}{n}+\frac{\left(x_{new}-\bar{x}\right)^{2}}{S_{xx}}}
\end{eqnarray*}

\end_inset


\end_layout

\begin_layout Standard
the expected value of new observation 
\begin_inset Formula $\hat{E}\left(Y\,|\,X=x_{new}\right)$
\end_inset

.
 This expectation is regression line but since the estimated regression
 line is a function of the data, then the line isn't the exactly the same
 as the true regression line.
 To reflect that, I want to calculate a confidence interval for where the
 true regression line should be.
\end_layout

\begin_layout Standard
I might instead be interested calculating a confidence interval for 
\begin_inset Formula $y_{new}$
\end_inset

, which I will call a 
\emph on
prediction interval
\emph default
 in an attempt to keep from being confused with the confidence interval
 of the regression line.
 Because we have 
\begin_inset Formula 
\[
y_{new}=\beta_{0}+\beta_{1}x_{new}+\epsilon_{new}
\]

\end_inset


\end_layout

\begin_layout Standard
Then my prediction interval will still be centered at 
\begin_inset Formula $\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}$
\end_inset

 but the the uncertainty should be the sum of the uncertainty associated
 with the estimates of 
\begin_inset Formula $\beta_{0}$
\end_inset

 and 
\begin_inset Formula $\beta_{1}$
\end_inset

 and the additional variability associated with 
\begin_inset Formula $\epsilon_{new}$
\end_inset

.
 In short, 
\begin_inset Formula 
\begin{eqnarray*}
\hat{Var}\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}+\epsilon\right) & = & \hat{Var}\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}\right)+\hat{Var}\left(\epsilon\right)\\
 & = & \hat{\sigma}^{2}\left(\frac{1}{n}+\frac{\left(x_{new}-\bar{x}\right)^{2}}{S_{xx}}\right)+\hat{\sigma}^{2}
\end{eqnarray*}

\end_inset

and the 
\begin_inset Formula $StdErr\left(\right)$
\end_inset

 of a new observation will be 
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
StdErr\left(\hat{y}_{new}\right)=\hat{\sigma}\sqrt{1+\frac{1}{n}+\frac{\left(x_{new}-\bar{x}\right)^{2}}{S_{xx}}}
\]

\end_inset


\end_layout

\begin_layout Standard
So the prediction interval for a new observation will be:
\begin_inset Formula 
\[
\left(\hat{\beta}_{0}+\hat{\beta}_{1}x_{new}\right)\pm t_{n-2}^{1-\alpha/2}\;\;\hat{\sigma}\sqrt{1+\frac{1}{n}+\frac{\left(x_{new}-\bar{x}\right)^{2}}{S_{xx}}}
\]

\end_inset


\end_layout

\begin_layout Scrap

\end_layout

\begin_layout Standard
To emphasize the difference between confidence regions (capturing where
 we believe the regression line to lay) versus prediction regions (where
 new data observations will lay) we note that as the sample size increases,
 the uncertainty as to where the regression line lays decreases, but the
 prediction intervals will always contain a minimum width due to the error
 associated with an individual observation.
 Below are confidence (red) and prediction (blue) regions for two different
 sample sizes.
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE, fig.height=4.5, fig.width=8, message=FALSE, warning=FALSE>>=
\end_layout

\begin_layout Plain Layout

library(ggplot2)
\end_layout

\begin_layout Plain Layout

set.seed(321)
\end_layout

\begin_layout Plain Layout

n <- 10 
\end_layout

\begin_layout Plain Layout

x <- seq(0,1,length=n) 
\end_layout

\begin_layout Plain Layout

y <- 10 + 3*x + rnorm(n, sd=1) 
\end_layout

\begin_layout Plain Layout

data <- data.frame(x=x, y=y, n=paste('n =', n)) 
\end_layout

\begin_layout Plain Layout

n <- 100 
\end_layout

\begin_layout Plain Layout

x <- seq(0,1,length=n) 
\end_layout

\begin_layout Plain Layout

y <- 10 + 3*x + rnorm(n, sd=1) 
\end_layout

\begin_layout Plain Layout

data <- rbind( data, data.frame(x=x,y=y,n=paste('n =', n))) 
\end_layout

\begin_layout Plain Layout

data$n <- factor(data$n)
\end_layout

\begin_layout Plain Layout

model <- lm(y~x*n, data=data) 
\end_layout

\begin_layout Plain Layout

data$y.hat <- fitted(model) 
\end_layout

\begin_layout Plain Layout

CI <- predict(model, interval='confidence') 
\end_layout

\begin_layout Plain Layout

PI <- predict(model, interval='prediction') 
\end_layout

\begin_layout Plain Layout

data$conf.lwr <- CI[,2]
\end_layout

\begin_layout Plain Layout

data$conf.upr <- CI[,3] 
\end_layout

\begin_layout Plain Layout

data$pred.lwr <- PI[,2]
\end_layout

\begin_layout Plain Layout

data$pred.upr <- PI[,3] 
\end_layout

\begin_layout Plain Layout

ggplot(data, aes(x=x)) +   
\end_layout

\begin_layout Plain Layout

  geom_point(aes(y=y)) +
\end_layout

\begin_layout Plain Layout

  geom_line(aes(y=y.hat)) +
\end_layout

\begin_layout Plain Layout

  geom_ribbon(aes(ymin=conf.lwr, ymax=conf.upr), fill='red', alpha=.2) +
\end_layout

\begin_layout Plain Layout

  geom_ribbon(aes(ymin=pred.lwr, ymax=pred.upr), fill='blue', alpha=.2) + 
  
\end_layout

\begin_layout Plain Layout

  facet_grid(.
 ~ n) + theme_bw()
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
In general, you will not want to calculate the confidence intervals and
 prediction intervals by hand.
 Fortunately R makes it easy to calculate the intervals.
 The function 
\family typewriter
predict()
\family default
 will calculate the point estimates along with confidence and prediction
 intervals.
 The function requires the 
\family typewriter
lm()
\family default
 output along with an optional data frame (if you want to predict values
 not in the original data).
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<fig.height=3, fig.width=5>>=
\end_layout

\begin_layout Plain Layout

# make up some data and graph it
\end_layout

\begin_layout Plain Layout

n <- 40
\end_layout

\begin_layout Plain Layout

sim.data <- data.frame( x = seq(0,1, length=n) ) %>%
\end_layout

\begin_layout Plain Layout

  mutate( y = 2 - 1*x + rnorm(n, sd=.2) )
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

ggplot(sim.data, aes(x=x, y=y)) + geom_point() + theme_bw()
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<>>=
\end_layout

\begin_layout Plain Layout

# fit the regression
\end_layout

\begin_layout Plain Layout

model <- lm(y~x, data=sim.data)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# display the first few predictions
\end_layout

\begin_layout Plain Layout

head( predict(model, interval="confidence") )
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# predict at x = 0.75
\end_layout

\begin_layout Plain Layout

predict(model, interval="prediction", newdata=data.frame(x=0.75))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Scrap
We can create a nice graph of the regression line and associated confidence
 and prediction regions using the following code in R:
\begin_inset Newline newline
\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=TRUE, fig.height=3, fig.width=5, message=FALSE, warning=FALSE>>=
\end_layout

\begin_layout Plain Layout

# ask for the confidence and prediction intervals
\end_layout

\begin_layout Plain Layout

conf.region <- predict(model, interval='confidence')
\end_layout

\begin_layout Plain Layout

pred.region <- predict(model, interval='prediction')
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# add them to my original data frame
\end_layout

\begin_layout Plain Layout

sim.data <- sim.data %>%
\end_layout

\begin_layout Plain Layout

  mutate( fit = fitted(model),
\end_layout

\begin_layout Plain Layout

          conf.lwr = conf.region[,2],
\end_layout

\begin_layout Plain Layout

          conf.upr = conf.region[,3],
\end_layout

\begin_layout Plain Layout

          pred.lwr = pred.region[,2],
\end_layout

\begin_layout Plain Layout

          pred.upr = pred.region[,3])
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=TRUE, fig.height=3, fig.width=5, message=FALSE, warning=FALSE>>=
\end_layout

\begin_layout Plain Layout

# make a nice plot
\end_layout

\begin_layout Plain Layout

ggplot(sim.data) +
\end_layout

\begin_layout Plain Layout

  geom_point( aes(x=x, y=y) ) +
\end_layout

\begin_layout Plain Layout

  geom_line(  aes(x=x, y=fit), col='red' ) +
\end_layout

\begin_layout Plain Layout

  geom_ribbon( aes(x=x, ymin=conf.lwr, ymax=conf.upr), fill='red',  alpha=.4)
 +
\end_layout

\begin_layout Plain Layout

  geom_ribbon( aes(x=x, ymin=pred.lwr, ymax=pred.upr), fill='blue', alpha=.4)
 +
\end_layout

\begin_layout Plain Layout

  theme_bw()
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
It is worth noting that these confidence intervals are all 
\emph on
point-wise 
\emph default
confidence intervals.
 If I want to calculate confidence or prediction intervals for a large number
 of 
\begin_inset Formula $x_{new}$
\end_inset

 values, then I have to deal with the multiple comparisons issue.
 Fortunately this is easy to do in the simple linear regression case.
 Instead of using the 
\begin_inset Formula $t_{n-2}^{1-\alpha/2}$
\end_inset

 quantile in the interval formulas, we should use 
\begin_inset Formula $W=\sqrt{2*F_{1-\alpha,\,2,\,n-2}}$
\end_inset

.
 Many books ignore this issue as does the 
\family typewriter
predict()
\family default
 function in R.
 
\end_layout

\begin_layout Section
Extrapolation 
\end_layout

\begin_layout Standard
The data observed will inform a researcher about the relationship between
 the x and y variables, but 
\emph on
only in the range for which you have data!
\emph default
 Below are the winning times of the men's 1500 meter Olympic race.
 
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=TRUE, fig.height=4, fig.width=8, warning=FALSE, message=FALSE>>=
\end_layout

\begin_layout Plain Layout

library(HSAUR2)
\end_layout

\begin_layout Plain Layout

data(men1500m)
\end_layout

\begin_layout Plain Layout

small <- men1500m %>% filter( year != 1896 )  # Remove the 1896 Olympics
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# fit the model and get the prediction interval
\end_layout

\begin_layout Plain Layout

model <- lm( time ~ year, data=small )
\end_layout

\begin_layout Plain Layout

small <- cbind(small, predict(model, interval='prediction') )
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

ggplot(small, aes(x=year, y=time, ymin=lwr, ymax=upr)) +
\end_layout

\begin_layout Plain Layout

  geom_point() +
\end_layout

\begin_layout Plain Layout

  geom_line( aes(y=fit), col='red' ) +
\end_layout

\begin_layout Plain Layout

  geom_ribbon( fill='red',  alpha=.4) + 
\end_layout

\begin_layout Plain Layout

  labs( x='Year', y='Time (s)', title='Winning times of Mens 1500 m' ) +
 theme_bw()
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
If we are interested in predicting the results of the 2008 and 2012 Olympic
 race, what would we predict?
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<>>=
\end_layout

\begin_layout Plain Layout

predict(model, 
\end_layout

\begin_layout Plain Layout

        newdata=data.frame(year=c(2008, 2012)), 
\end_layout

\begin_layout Plain Layout

        interval="prediction")
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We can compare the predicted intervals with the time actually recorded by
 the winner of the mens 1500m.
 In Beijing 2008, Rashid Ramzi from Brunei won the event in 212.94 seconds
 and in London 2012 Taoufik Makhloufi from Algeria won in 214.08 seconds.
 Both times are within the corresponding prediction intervals, but clearly
 the linear relationship must eventually change and therefore our regression
 could not possibly predict the winning time of the 3112 race.
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<>>=
\end_layout

\begin_layout Plain Layout

predict(model, newdata=data.frame(year=c(3112)), interval="prediction")
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Section
Checking Model Assumptions
\end_layout

\begin_layout Standard
As in the anova analysis, we want to be able to check the model assumptions.
 To do this, we will examine the residuals 
\begin_inset Formula 
\[
e_{i}=y_{i}-\hat{y}_{i}
\]

\end_inset

for normality using a QQ-plot as we did in Anova.
 To address the constant variance and linearity assumptions we will look
 at scatterplots of the residuals vs the fitted values 
\begin_inset Formula $\hat{y}_{i}$
\end_inset

.
 For the regression to be valid, we want the scatterplot to show no discernible
 trend.
 There are two patterns that commonly show up that indicate a violation
 of the regression assumptions.
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE, fig.height=4, fig.width=10>>=
\end_layout

\begin_layout Plain Layout

set.seed(2233);
\end_layout

\begin_layout Plain Layout

par(mfrow=c(1,3));
\end_layout

\begin_layout Plain Layout

n <- 20;
\end_layout

\begin_layout Plain Layout

x <- seq(0,1,length=n);
\end_layout

\begin_layout Plain Layout

data <- data.frame(
\end_layout

\begin_layout Plain Layout

  Fitted=c(x,x,x),
\end_layout

\begin_layout Plain Layout

  Residual=c(rnorm(n,0,.25), rnorm(n,(2*x-1)^2-.375, .2), rnorm(n,0,x*.45)),
 
\end_layout

\begin_layout Plain Layout

  Type=factor(rep(1:3, each=n), labels=c('No Trend', 'Non-Linear', 'Non-Constant
 Variance') ));
\end_layout

\begin_layout Plain Layout

for(i in 1:3){
\end_layout

\begin_layout Plain Layout

  index <- 1:n + n*(i-1);
\end_layout

\begin_layout Plain Layout

  plot(data$Fitted[index], data$Residual[index], 
\end_layout

\begin_layout Plain Layout

	   xlab='Fitted', ylab='Residual', main=data$Type[index[1]] );
\end_layout

\begin_layout Plain Layout

  abline(0,0, lty=2);
\end_layout

\begin_layout Plain Layout

}
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
To illustrate this, we'll look at data about the height and weight values
 for women between 30 and 39.
 (The data presented is actually the average weight for women of given heights,
 but is a useful example).
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<fig.height=3.5, fig.width=5>>=
\end_layout

\begin_layout Plain Layout

data('women')
\end_layout

\begin_layout Plain Layout

str(women)
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

# fit the regression line and add that info to my data frame
\end_layout

\begin_layout Plain Layout

model <- lm(weight ~ height, data=women)
\end_layout

\begin_layout Plain Layout

women <- women %>%
\end_layout

\begin_layout Plain Layout

  mutate( fit   = fitted(model),
\end_layout

\begin_layout Plain Layout

          resid = resid(model)  )
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\begin_inset Newline newline
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<fig.height=3.5, fig.width=5>>=
\end_layout

\begin_layout Plain Layout

ggplot(women) +
\end_layout

\begin_layout Plain Layout

  geom_point(aes(x=height, y = weight )) +
\end_layout

\begin_layout Plain Layout

  geom_line( aes(x=height, y = fit    )) +
\end_layout

\begin_layout Plain Layout

  labs( x='Height', y='Weight', 
\end_layout

\begin_layout Plain Layout

        title='Average Weight vs Height of US Women 30-39' ) +
\end_layout

\begin_layout Plain Layout

  theme_bw()
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
If we squint at this graph, we see that the data are not perfectly linear
 and there appears to be some curvature.
 It isn't particularly clear from this graph however.
 However, when we look at the residuals vs fitted values and immediately
 conclude that the linearity assumption is violated.
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<fig.height=3, fig.width=8>>=
\end_layout

\begin_layout Plain Layout

ggplot(women, aes( x=fit, y=resid )) +
\end_layout

\begin_layout Plain Layout

  geom_point() +
\end_layout

\begin_layout Plain Layout

  labs(title='Residuals vs Fitted', x='Fitted', y='Residual') + theme_bw()
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
This sort of graph is useful enough that R provides a quick way to create
 it.
 The function 
\family typewriter
plot( lm.object ) 
\family default
will take the input linear model and produce 6 diagnostic plots.
 If we've loaded the 
\family typewriter
ggfortify 
\family default
package, then the function 
\family typewriter
autoplot()
\family default
 will do the same thing.
\begin_inset Newline newline
\end_inset


\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<fig.height=3, fig.width=6>>=
\end_layout

\begin_layout Plain Layout

autoplot(model, which=c(1,2))
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Example: Cherry Trees
\end_layout

\begin_layout Standard
To see the entire regression process, we consider the problem of predicting
 the volume of lumber produced by a cherry tree of a given diameter.
 The data are given in a dataset pre-loaded in R called 
\family typewriter
trees
\family default
.
\end_layout

\begin_layout Section
Influential Points
\end_layout

\begin_layout Standard
Sometimes a dataset will contain one observation that has a large effect
 on the outcome of the model.
 Consider the following datasets where the red denotes a highly influential
 point and the red line is the regression line including the point.
 
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE, fig.height=4, fig.width=8>>=
\end_layout

\begin_layout Plain Layout

par(mfrow=c(1,2))
\end_layout

\begin_layout Plain Layout

x <- c( 9, 10, 11, 12)
\end_layout

\begin_layout Plain Layout

y <- c(15, 17, 16, 18)
\end_layout

\begin_layout Plain Layout

model <- lm(y ~ x)
\end_layout

\begin_layout Plain Layout

model.1 <- lm(c(y,28) ~ c(x,2))
\end_layout

\begin_layout Plain Layout

model.2 <- lm(c(y,28) ~ c(x,10.5))
\end_layout

\begin_layout Plain Layout

plot(x,y, xlim=c(0,14), ylim=c(15,30))
\end_layout

\begin_layout Plain Layout

points(2, 28, pch=2, col='red')
\end_layout

\begin_layout Plain Layout

abline(coef(model))
\end_layout

\begin_layout Plain Layout

abline(coef(model.1), col='red', lty=2)
\end_layout

\begin_layout Plain Layout

plot(x,y, xlim=c(8,13), ylim=c(15,30))
\end_layout

\begin_layout Plain Layout

points(10.5, 28, pch=2, col='red')
\end_layout

\begin_layout Plain Layout

abline(coef(model))
\end_layout

\begin_layout Plain Layout

abline(coef(model.2), col='red', lty=2)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
The question of what to do with influential points is not easy to answer.
 Sometimes these are data points that are a result of lab technician error
 and should be removed.
 Sometimes they are the result of an important process that is not well
 understood by the researcher.
 It is up to the scientist to figure out which is the case and take appropriate
 action.
 
\end_layout

\begin_layout Standard
One solution is to run the analysis both with and without the influential
 point and see how much it affects your inferences.
\end_layout

\begin_layout Section
Transformations
\end_layout

\begin_layout Standard
When the normality or constant variance assumption is violated, sometimes
 it is possible to 
\emph on
transform
\emph default
 the data to make it satisfy the assumption.
 Often times count data is analyzed as log(count) and weights are analyzed
 after taking a square root or cube root transform.
 
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE, fig.height=5, fig.width=9>>=
\end_layout

\begin_layout Plain Layout

x <- seq(0, 10, length=100)
\end_layout

\begin_layout Plain Layout

plot(c(0,10), c(-2,6), type='n', xlab='x', ylab='y')
\end_layout

\begin_layout Plain Layout

lines(x, log(x), lwd=2, col=1, lty=1)
\end_layout

\begin_layout Plain Layout

lines(x, sqrt(x), lwd=2, col=2, lty=2)
\end_layout

\begin_layout Plain Layout

lines(x, 1/x, lwd=3, col=3, lty=3)
\end_layout

\begin_layout Plain Layout

legend(1,6, legend=c('log(x)', 'sqrt(x)', '1/x'), lty=1:3, col=1:3)
\end_layout

\begin_layout Plain Layout

abline(h=0)
\end_layout

\begin_layout Plain Layout

abline(v=0)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
We have the option of either transforming the x-variable or transforming
 the y-variable or possibly both.
 One thing to keep in mind, however, is that transforming the x-variable
 only effects the linearity of the relationship.
 Transforming the y-variable effects both the linearity and the variance.
 
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE, fig.height=4, fig.width=9>>=
\end_layout

\begin_layout Plain Layout

set.seed(-838)
\end_layout

\begin_layout Plain Layout

par(mfrow=c(1,3))
\end_layout

\begin_layout Plain Layout

n <- 40
\end_layout

\begin_layout Plain Layout

x <- seq(1,30, length=n);
\end_layout

\begin_layout Plain Layout

y <- 2 + 30*exp((30-x)/10) + rnorm(n, sd=20)
\end_layout

\begin_layout Plain Layout

y <- abs(y)
\end_layout

\begin_layout Plain Layout

plot(x,y); abline(coef(lm(y~x)));
\end_layout

\begin_layout Plain Layout

plot(x, log(y)); abline(coef(lm(I(log(y))~x)));
\end_layout

\begin_layout Plain Layout

plot(x^(1/3), y); abline(coef(lm(y~I(x^(1/3)))));
\end_layout

\begin_layout Plain Layout

mydata <- data.frame(x=x, y=y)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Unfortunately it is not always obvious what transformation is most appropriate.
 The Box-Cox family of transformations for the y-variable is 
\begin_inset Formula 
\begin{eqnarray*}
f(y\,|\,\lambda) & = & \begin{cases}
y^{\lambda} & \;\;\textrm{if}\,\,\lambda\ne0\\
\log y & \;\;\textrm{if}\,\,\lambda=0
\end{cases}
\end{eqnarray*}

\end_inset

 which includes squaring (
\begin_inset Formula $\lambda=2)$
\end_inset

, square root 
\begin_inset Formula $\left(\lambda=1/2\right)$
\end_inset

 and as 
\begin_inset Formula $\lambda\to0$
\end_inset

 the transformation converges to 
\begin_inset Formula $\log y$
\end_inset

.
 (To do this correctly we should define the transformation in a more complicated
 fashion, but that level of detail is unnecessary here.) The transformation
 is selected by looking at the profile log-likelihood value of different
 values of 
\begin_inset Formula $\lambda$
\end_inset

 and we want to use the 
\begin_inset Formula $\lambda$
\end_inset

 that maximizes the log-likelihood.
 
\end_layout

\begin_layout Standard
Of course, we also want to use a transformation that isn't completely obscure
 and is commonly used in the scientific field, so square roots, reciprocals,
 and logs are preferred.
\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<echo=FALSE, fig.height=4, fig.width=8>>=
\end_layout

\begin_layout Plain Layout

set.seed(-838)
\end_layout

\begin_layout Plain Layout

par(mfrow=c(1,2))
\end_layout

\begin_layout Plain Layout

n <- 40
\end_layout

\begin_layout Plain Layout

x <- seq(0,30, length=n)
\end_layout

\begin_layout Plain Layout

y <- 2+ x*exp(rnorm(n))
\end_layout

\begin_layout Plain Layout

plot(x,y); abline(coef(lm(y~x)));
\end_layout

\begin_layout Plain Layout

plot(x, log(y)); abline(coef(lm(I(log(y))~x)));
\end_layout

\begin_layout Plain Layout

mydata <- data.frame(x=x, y=y)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Scrap
\begin_inset Box Frameless
position "t"
hor_pos "c"
has_inner_box 1
inner_pos "t"
use_parbox 0
use_makebox 0
width "100col%"
special "none"
height "1in"
height_special "totalheight"
status open

\begin_layout Plain Layout
\begin_inset ERT
status open

\begin_layout Plain Layout

<<fig.height=5, fig.width=8>>=
\end_layout

\begin_layout Plain Layout

library(MASS)
\end_layout

\begin_layout Plain Layout

str(mydata)
\end_layout

\begin_layout Plain Layout

boxcox(y~x, data=mydata, plotit=TRUE)
\end_layout

\begin_layout Plain Layout

@
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Standard
Here we see the resulting confidence interval for 
\begin_inset Formula $\lambda$
\end_inset

 contains 
\begin_inset Formula $0$
\end_inset

, so a 
\begin_inset Formula $\log$
\end_inset

 transformation would be most appropriate.
\end_layout

\begin_layout Standard
In general, deciding on a transformation to use is often a trade-off between
 statistical pragmatism and interpretability.
 In cases that a transformation is not possible, or the interpretation is
 difficult, it is necessary to build more complicated models that are interpreta
ble.
\end_layout

\end_body
\end_document
